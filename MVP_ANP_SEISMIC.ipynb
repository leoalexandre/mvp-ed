{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPh1FLASyMvg8svXGsCoWa7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leoalexandre/mvp-ed/blob/main/MVP_ANP_SEISMIC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MVP de Análise de Dados e Boas Práticas\n",
        "Por Leonardo da Silva Alexandre"
      ],
      "metadata": {
        "id": "UaeQJoTO3DqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.   Definição do Problema"
      ],
      "metadata": {
        "id": "FlRtOPce4-cz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O dataset utilizado neste projeto foi retirado do site da Agência Nacional do Petróleo (ANP). A criação veio a partir da tabela de atributos retirada do shapefile de todos os programas sísmicos gerados pelo mercado de óleo e gás brasileiro, somado a aplicação de algumas regras presentes na legislação brasileira gerida pela ANP. A legislação nacional pode ser encontrada dentro dos sites da ANP. O shapefile está alocado mais precisamente em:\n",
        "\n",
        "https://www.gov.br/anp/pt-br/assuntos/exploracao-e-producao-de-oleo-e-gas/dados-tecnicos/acervo-de-dados\n",
        "\n",
        "O dataset apresenta atributos relacionados aos programas sísmicos com relação a datas, localização, volume, valor, empresas proprietárias dos dados e período de confidencialidade. Seu objetivo é vislumbrar novos processamentos ou aquisições sísmicas com maior potencial de interesse do mercado a partir da identificação de uma ausência de dados de processamento e suas versões em áreas das bacias sedimentares brasileiras que apresentem maior visibilidade da indústria de óleo e gás.\n",
        "Informações sobre atributos:\n",
        "\n",
        "  1. **VOLUME_GB** – Volume da soma dos arquivos do projeto sísmico;\n",
        "  2. **VALOR_UD** – Valor em UD do projeto sísmico;\n",
        "  3. **PROJETO** – Projeto sísmico oriundo de um programa sísmico;\n",
        "  4. **TIPO_PROCESSAMENTO** – Tipo de processamento sísmico realizado no programa sísmico;\n",
        "  5. **PUBLICIDADE** – Classificação do programa sísmico em público ou confidencial;\n",
        "  6. **PROGRAMA** – Programa sísmico criado pela ANP por solicitação da empresa;\n",
        "  7. **TIPO_PROGRAMA** – Classificação do programa sísmico em Exclusivo (Pré-98), Exclusivo, Não-Exclusivo ou de fomento;\n",
        "  8. **TECNOLOGIA** – Dimensionalidade do dado sísmico;\n",
        "  9. **INÍCIO** – Data de início do programa;\n",
        "  10. **TÉRMINO** – Data de término do programa;\n",
        "  11. **DATA_PUBLICIDADE** – Data na qual o programa se torna público perante a legislação vigente;\n",
        "  12. **BLOCO** – Bloco exploratório onde está localizado o programa sísmico;\n",
        "  13. **CAMPO** – Campo de exploração onde está localizado o programa sísmico;\n",
        "  14. **BACIA** – Bacia geológica onde está localizado o programa sísmico;\n",
        "  15. **EAD** – Empresa de Aquisição de Dados responsável pelo programa sísmico;\n",
        "  16. **OPERADORA** – Empresa Operadora detentora dos direitos sobre os dados do programa sísmico."
      ],
      "metadata": {
        "id": "25Ril6hV3foz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as ms # para tratamento de missings\n",
        "from matplotlib import cm\n",
        "from pandas import set_option\n",
        "from pandas.plotting import scatter_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "Gv0aY0lF4qYN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configuração para não exibir os warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "q5z0ZXw6GW8H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Carga de Dados"
      ],
      "metadata": {
        "id": "b3RyB2lmMpZk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iremos usar o pacote Pandas (Python Data Analysis Library) para carregar de um arquivo .csv sem cabeçalho disponível online.\n",
        "\n",
        "Com o dataset carregado, iremos explorá-lo um pouco.\n",
        "\n",
        "MUDAR!!!!!!"
      ],
      "metadata": {
        "id": "t-03uyotM4vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carrega arquivo csv usando Pandas usando uma URL\n",
        "\n",
        "# Informa a URL de importação do dataset\n",
        "url = \"https://github.com/leoalexandre/mvp_adbp/blob/main/SISMICAS_ANP_EDIT.txt\"\n",
        "\n",
        "# Informa o cabeçalho das colunas\n",
        "colunas = ['VOLUME_GB', 'VALOR_UD', 'PROJETO', 'TIPO_PROCESSAMENTO', 'PUBLICIDADE', 'PROGRAMA', 'TIPO_PROGRAMA', 'TECNOLOGIA', 'INICIO', 'TERMINO', 'DATA_PUBLICIDADE', 'BLOCO', 'CAMPO', 'BACIA', 'EAD', 'OPERADORA']\n",
        "\n",
        "# Lê o arquivo utilizando as colunas informadas\n",
        "dataset = pd.read_csv(url, names=colunas, skiprows=1, delimiter=',')"
      ],
      "metadata": {
        "id": "Z_ggZeDINj9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "mOB4xDZ2OjhX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}